ğŸ“° News Sentiment Analysis

ğŸ¯ Objective
Classify news headlines into Positive, Negative, or Neutral sentiments using ML and NLP techniques.

ğŸ“Š Dataset
Source: Kaggle
Text: News headlines
Labels: Positive, Negative, Neutral
Slight class imbalance (more Neutral samples)

ğŸ§¹ Preprocessing
Removed nulls, lowercased text
Cleaned punctuation & digits (Regex)
Tokenized & lemmatized (nltk, spaCy)
Removed stopwords
Label-encoded sentiments

ğŸ§  Models Used
Classical: Logistic Regression, Naive Bayes, SVM (best among these)
Deep Learning: LSTM with Keras
Transformer: Fine-tuned BERT (best overall) using HuggingFace

ğŸ“ˆ Evaluation
Metrics: Accuracy, Precision, Recall, F1 Score
BERT had highest F1 score, SVM was a strong classical alternative
Visuals: Loss vs Accuracy plots (LSTM, BERT), Confusion Matrix

âš ï¸ Challenges
Class imbalance â†’ used class weights
LSTM overfitting â†’ handled with dropout & early stopping
BERT training needs GPU â†’ used Colab

âœ… Conclusion
BERT delivered the best results. SVM worked well for faster, low-resource scenarios. The pipeline is solid for scaling or real-time use.
